{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Switch Off Pretty Printing of Output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pprint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open, Read and Close Data_1 Textfile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'NLP is important for scientific, economic, social, and cultural reasons. NLP is experiencing rapid growth as its theories and methods are deployed in a variety of new language technologies. For this reason it is important for a wide range of people to have a working knowledge of NLP. Within industry, this includes people in human-computer interaction, business information analysis, and web software development. Within academia, it includes people in areas from humanities computing and corpus linguistics through to computer science and artificial intelligence. (To many people in academia, NLP is known by the name of \"Computational Linguistics.\")'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file1 = \"data/Data_1.txt\"\n",
    "with open(file=data_file1) as f:\n",
    "    text = f.read()\n",
    "\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q1. Form Tokenisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Demonstrate sentence segmentation and report the output. (6 marks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Segmentation using Split Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP is important for scientific, economic, social, and cultural reasons', 'NLP is experiencing rapid growth as its theories and methods are deployed in a variety of new language technologies', 'For this reason it is important for a wide range of people to have a working knowledge of NLP', 'Within industry, this includes people in human-computer interaction, business information analysis, and web software development', 'Within academia, it includes people in areas from humanities computing and corpus linguistics through to computer science and artificial intelligence', '(To many people in academia, NLP is known by the name of \"Computational Linguistics.\")']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = text.split(\". \")\n",
    "\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Segmentation using Regular Expression Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP is important for scientific, economic, social, and cultural reasons', 'NLP is experiencing rapid growth as its theories and methods are deployed in a variety of new language technologies', 'For this reason it is important for a wide range of people to have a working knowledge of NLP', 'Within industry, this includes people in human-computer interaction, business information analysis, and web software development', 'Within academia, it includes people in areas from humanities computing and corpus linguistics through to computer science and artificial intelligence', '(To many people in academia, NLP is known by the name of \"Computational Linguistics.\")']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentences = re.split(r\"[.!?] \", text)\n",
    "\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Segmentation using NLTK Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP is important for scientific, economic, social, and cultural reasons.', 'NLP is experiencing rapid growth as its theories and methods are deployed in a variety of new language technologies.', 'For this reason it is important for a wide range of people to have a working knowledge of NLP.', 'Within industry, this includes people in human-computer interaction, business information analysis, and web software development.', 'Within academia, it includes people in areas from humanities computing and corpus linguistics through to computer science and artificial intelligence.', '(To many people in academia, NLP is known by the name of \"Computational Linguistics.\")']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Demonstrate word tokenisation using the split function, Regular Expression and NLTK packages separately and report the output. (10 marks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Tokenisation using Split Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP', 'is', 'important', 'for', 'scientific,', 'economic,', 'social,', 'and', 'cultural', 'reasons.', 'NLP', 'is', 'experiencing', 'rapid', 'growth', 'as', 'its', 'theories', 'and', 'methods', 'are', 'deployed', 'in', 'a', 'variety', 'of', 'new', 'language', 'technologies.', 'For', 'this', 'reason', 'it', 'is', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'working', 'knowledge', 'of', 'NLP.', 'Within', 'industry,', 'this', 'includes', 'people', 'in', 'human-computer', 'interaction,', 'business', 'information', 'analysis,', 'and', 'web', 'software', 'development.', 'Within', 'academia,', 'it', 'includes', 'people', 'in', 'areas', 'from', 'humanities', 'computing', 'and', 'corpus', 'linguistics', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence.', '(To', 'many', 'people', 'in', 'academia,', 'NLP', 'is', 'known', 'by', 'the', 'name', 'of', '\"Computational', 'Linguistics.\")']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split()\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Tokenisation using Regular Expression Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP', 'is', 'important', 'for', 'scientific,', 'economic,', 'social,', 'and', 'cultural', 'reasons.', 'NLP', 'is', 'experiencing', 'rapid', 'growth', 'as', 'its', 'theories', 'and', 'methods', 'are', 'deployed', 'in', 'a', 'variety', 'of', 'new', 'language', 'technologies.', 'For', 'this', 'reason', 'it', 'is', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'working', 'knowledge', 'of', 'NLP.', 'Within', 'industry,', 'this', 'includes', 'people', 'in', 'human-computer', 'interaction,', 'business', 'information', 'analysis,', 'and', 'web', 'software', 'development.', 'Within', 'academia,', 'it', 'includes', 'people', 'in', 'areas', 'from', 'humanities', 'computing', 'and', 'corpus', 'linguistics', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence.', '(To', 'many', 'people', 'in', 'academia,', 'NLP', 'is', 'known', 'by', 'the', 'name', 'of', '\"Computational', 'Linguistics.\")']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = re.split(r\" \", text)\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP', 'is', 'important', 'for', 'scientific', 'economic', 'social', 'and', 'cultural', 'reasons', 'NLP', 'is', 'experiencing', 'rapid', 'growth', 'as', 'its', 'theories', 'and', 'methods', 'are', 'deployed', 'in', 'a', 'variety', 'of', 'new', 'language', 'technologies', 'For', 'this', 'reason', 'it', 'is', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'working', 'knowledge', 'of', 'NLP', 'Within', 'industry', 'this', 'includes', 'people', 'in', 'human', 'computer', 'interaction', 'business', 'information', 'analysis', 'and', 'web', 'software', 'development', 'Within', 'academia', 'it', 'includes', 'people', 'in', 'areas', 'from', 'humanities', 'computing', 'and', 'corpus', 'linguistics', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence', 'To', 'many', 'people', 'in', 'academia', 'NLP', 'is', 'known', 'by', 'the', 'name', 'of', 'Computational', 'Linguistics', '']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = re.split(r\"\\W+\", text)\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Tokenisation using NLTK Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP', 'is', 'important', 'for', 'scientific', ',', 'economic', ',', 'social', ',', 'and', 'cultural', 'reasons', '.', 'NLP', 'is', 'experiencing', 'rapid', 'growth', 'as', 'its', 'theories', 'and', 'methods', 'are', 'deployed', 'in', 'a', 'variety', 'of', 'new', 'language', 'technologies', '.', 'For', 'this', 'reason', 'it', 'is', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'working', 'knowledge', 'of', 'NLP', '.', 'Within', 'industry', ',', 'this', 'includes', 'people', 'in', 'human-computer', 'interaction', ',', 'business', 'information', 'analysis', ',', 'and', 'web', 'software', 'development', '.', 'Within', 'academia', ',', 'it', 'includes', 'people', 'in', 'areas', 'from', 'humanities', 'computing', 'and', 'corpus', 'linguistics', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence', '.', '(', 'To', 'many', 'people', 'in', 'academia', ',', 'NLP', 'is', 'known', 'by', 'the', 'name', 'of', '``', 'Computational', 'Linguistics', '.', \"''\", ')']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Tokenisation using TextBlob Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "WordList(['NLP', 'is', 'important', 'for', 'scientific', 'economic', 'social', 'and', 'cultural', 'reasons', 'NLP', 'is', 'experiencing', 'rapid', 'growth', 'as', 'its', 'theories', 'and', 'methods', 'are', 'deployed', 'in', 'a', 'variety', 'of', 'new', 'language', 'technologies', 'For', 'this', 'reason', 'it', 'is', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'working', 'knowledge', 'of', 'NLP', 'Within', 'industry', 'this', 'includes', 'people', 'in', 'human-computer', 'interaction', 'business', 'information', 'analysis', 'and', 'web', 'software', 'development', 'Within', 'academia', 'it', 'includes', 'people', 'in', 'areas', 'from', 'humanities', 'computing', 'and', 'corpus', 'linguistics', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence', 'To', 'many', 'people', 'in', 'academia', 'NLP', 'is', 'known', 'by', 'the', 'name', 'of', 'Computational', 'Linguistics'])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(text)\n",
    "words = blob.words\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q2. Form Word Stemming"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Demonstrate word stemming using Regular Expression, Porter Stemmer and Lancaster Stemmer and report the output. (12 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Basic Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP', 'i', 'important', 'for', 'scientific', ',', 'economic', ',', 'social', ',', 'and', 'cultural', 'reason', '.', 'NLP', 'i', 'experienc', 'rapid', 'growth', 'a', 'it', 'theor', 'and', 'method', 'are', 'deploy', 'in', 'a', 'variety', 'of', 'new', 'language', 'technolog', '.', 'For', 'thi', 'reason', 'it', 'i', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'work', 'knowledge', 'of', 'NLP', '.', 'Within', 'industry', ',', 'thi', 'includ', 'people', 'in', 'human-computer', 'interaction', ',', 'busines', 'information', 'analysi', ',', 'and', 'web', 'software', 'develop', '.', 'Within', 'academia', ',', 'it', 'includ', 'people', 'in', 'area', 'from', 'humanit', 'comput', 'and', 'corpu', 'linguistic', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence', '.', '(', 'To', 'many', 'people', 'in', 'academia', ',', 'NLP', 'i', 'known', 'by', 'the', 'name', 'of', '``', 'Computational', 'Linguistic', '.', \"''\", ')']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffixes = [\"ing\", \"ly\", \"ed\", \"ious\", \"ies\", \"ive\", \"es\", \"s\", \"ment\"]\n",
    "\n",
    "def stem(word):\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "stemmed_words = [stem(word) for word in words]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Regular Expression Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP', 'i', 'important', 'for', 'scientific', ',', 'economic', ',', 'social', ',', 'and', 'cultural', 'reason', '.', 'NLP', 'i', 'experienc', 'rapid', 'growth', 'a', 'it', 'theor', 'and', 'method', 'are', 'deploy', 'in', 'a', 'variety', 'of', 'new', 'language', 'technolog', '.', 'For', 'thi', 'reason', 'it', 'i', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'work', 'knowledge', 'of', 'NLP', '.', 'Within', 'industry', ',', 'thi', 'includ', 'people', 'in', 'human-computer', 'interaction', ',', 'busines', 'information', 'analysi', ',', 'and', 'web', 'software', 'develop', '.', 'Within', 'academia', ',', 'it', 'includ', 'people', 'in', 'area', 'from', 'humanit', 'comput', 'and', 'corpu', 'linguistic', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence', '.', '(', 'To', 'many', 'people', 'in', 'academia', ',', 'NLP', 'i', 'known', 'by', 'the', 'name', 'of', '``', 'Computational', 'Linguistic', '.', \"''\", ')']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_stem_pattern = r\"^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$\"\n",
    "stemmed_words = [\n",
    "    re.findall(split_stem_pattern, word)[0][0]\n",
    "    for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP', 'i', 'important', 'for', 'scientific', ',', 'economic', ',', 'social', ',', 'and', 'cultural', 'reason', '.', 'NLP', 'i', 'experienc', 'rapid', 'growth', 'a', 'it', 'theor', 'and', 'method', 'are', 'deploy', 'in', 'a', 'variety', 'of', 'new', 'language', 'technolog', '.', 'For', 'thi', 'reason', 'it', 'i', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'work', 'knowledge', 'of', 'NLP', '.', 'Within', 'industry', ',', 'thi', 'includ', 'people', 'in', 'human-computer', 'interaction', ',', 'busines', 'information', 'analysi', ',', 'and', 'web', 'software', 'develop', '.', 'Within', 'academia', ',', 'it', 'includ', 'people', 'in', 'area', 'from', 'humanit', 'comput', 'and', 'corpu', 'linguistic', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence', '.', '(', 'To', 'many', 'people', 'in', 'academia', ',', 'NLP', 'i', 'known', 'by', 'the', 'name', 'of', '``', 'Computational', 'Linguistic', '.', \"''\", ')']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_pattern = r\"(ing|ly|ed|ious|ies|ive|es|s|ment)$\"\n",
    "stemmed_words = [\n",
    "    re.sub(suffix_pattern, \"\", word)\n",
    "    for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Porter Stemmer Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['nlp', 'is', 'import', 'for', 'scientif', ',', 'econom', ',', 'social', ',', 'and', 'cultur', 'reason', '.', 'nlp', 'is', 'experienc', 'rapid', 'growth', 'as', 'it', 'theori', 'and', 'method', 'are', 'deploy', 'in', 'a', 'varieti', 'of', 'new', 'languag', 'technolog', '.', 'for', 'thi', 'reason', 'it', 'is', 'import', 'for', 'a', 'wide', 'rang', 'of', 'peopl', 'to', 'have', 'a', 'work', 'knowledg', 'of', 'nlp', '.', 'within', 'industri', ',', 'thi', 'includ', 'peopl', 'in', 'human-comput', 'interact', ',', 'busi', 'inform', 'analysi', ',', 'and', 'web', 'softwar', 'develop', '.', 'within', 'academia', ',', 'it', 'includ', 'peopl', 'in', 'area', 'from', 'human', 'comput', 'and', 'corpu', 'linguist', 'through', 'to', 'comput', 'scienc', 'and', 'artifici', 'intellig', '.', '(', 'to', 'mani', 'peopl', 'in', 'academia', ',', 'nlp', 'is', 'known', 'by', 'the', 'name', 'of', '``', 'comput', 'linguist', '.', \"''\", ')']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer = nltk.PorterStemmer()\n",
    "stemmed_words = [\n",
    "    porter_stemmer.stem(word) for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Lancaster Stemmer Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['nlp', 'is', 'import', 'for', 'sci', ',', 'econom', ',', 'soc', ',', 'and', 'cult', 'reason', '.', 'nlp', 'is', 'expery', 'rapid', 'grow', 'as', 'it', 'the', 'and', 'method', 'ar', 'deploy', 'in', 'a', 'vary', 'of', 'new', 'langu', 'technolog', '.', 'for', 'thi', 'reason', 'it', 'is', 'import', 'for', 'a', 'wid', 'rang', 'of', 'peopl', 'to', 'hav', 'a', 'work', 'knowledg', 'of', 'nlp', '.', 'within', 'industry', ',', 'thi', 'includ', 'peopl', 'in', 'human-computer', 'interact', ',', 'busy', 'inform', 'analys', ',', 'and', 'web', 'softw', 'develop', '.', 'within', 'academ', ',', 'it', 'includ', 'peopl', 'in', 'area', 'from', 'hum', 'comput', 'and', 'corp', 'lingu', 'through', 'to', 'comput', 'sci', 'and', 'art', 'intellig', '.', '(', 'to', 'many', 'peopl', 'in', 'academ', ',', 'nlp', 'is', 'known', 'by', 'the', 'nam', 'of', '``', 'comput', 'lingu', '.', \"''\", ')']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster_stemmer = nltk.LancasterStemmer()\n",
    "stemmed_words = [\n",
    "    lancaster_stemmer.stem(word) for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Snowball Stemmer Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['nlp', 'is', 'import', 'for', 'scientif', ',', 'econom', ',', 'social', ',', 'and', 'cultur', 'reason', '.', 'nlp', 'is', 'experienc', 'rapid', 'growth', 'as', 'it', 'theori', 'and', 'method', 'are', 'deploy', 'in', 'a', 'varieti', 'of', 'new', 'languag', 'technolog', '.', 'for', 'this', 'reason', 'it', 'is', 'import', 'for', 'a', 'wide', 'rang', 'of', 'peopl', 'to', 'have', 'a', 'work', 'knowledg', 'of', 'nlp', '.', 'within', 'industri', ',', 'this', 'includ', 'peopl', 'in', 'human-comput', 'interact', ',', 'busi', 'inform', 'analysi', ',', 'and', 'web', 'softwar', 'develop', '.', 'within', 'academia', ',', 'it', 'includ', 'peopl', 'in', 'area', 'from', 'human', 'comput', 'and', 'corpus', 'linguist', 'through', 'to', 'comput', 'scienc', 'and', 'artifici', 'intellig', '.', '(', 'to', 'mani', 'peopl', 'in', 'academia', ',', 'nlp', 'is', 'known', 'by', 'the', 'name', 'of', '``', 'comput', 'linguist', '.', \"''\", ')']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer = nltk.SnowballStemmer(language=\"english\")\n",
    "stemmed_words = [\n",
    "    snowball_stemmer.stem(word) for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q3. Filter Stop Words and Punctuation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Demonstrate stop words and punctuations removal from the given text corpus and report the output suitably. (12 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Words before Filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['nlp', 'is', 'important', 'for', 'scientific', ',', 'economic', ',', 'social', ',', 'and', 'cultural', 'reasons', '.', 'nlp', 'is', 'experiencing', 'rapid', 'growth', 'as', 'its', 'theories', 'and', 'methods', 'are', 'deployed', 'in', 'a', 'variety', 'of', 'new', 'language', 'technologies', '.', 'for', 'this', 'reason', 'it', 'is', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'working', 'knowledge', 'of', 'nlp', '.', 'within', 'industry', ',', 'this', 'includes', 'people', 'in', 'human-computer', 'interaction', ',', 'business', 'information', 'analysis', ',', 'and', 'web', 'software', 'development', '.', 'within', 'academia', ',', 'it', 'includes', 'people', 'in', 'areas', 'from', 'humanities', 'computing', 'and', 'corpus', 'linguistics', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence', '.', '(', 'to', 'many', 'people', 'in', 'academia', ',', 'nlp', 'is', 'known', 'by', 'the', 'name', 'of', '``', 'computational', 'linguistics', '.', \"''\", ')']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text.lower())\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stop Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Negation Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['no', 'nor', 'not', 'don', \"don't\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negation_word_pattern = (\n",
    "    r\"^(nor?|.*(not|'t|[dst]n)|(ai|are|do|have|sha|were|wo)n)$\"\n",
    ")\n",
    "r = re.compile(negation_word_pattern)\n",
    "negation_word = list(filter(r.match, stop_words))\n",
    "\n",
    "negation_word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Words and Punctuations to be Removed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ma', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '``', \"''\"]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words = [\n",
    "    word\n",
    "    for word in stop_words\n",
    "    if word not in negation_word\n",
    "]\n",
    "punctuations = list(string.punctuation)\n",
    "double_quotes = [\"``\", \"''\"]\n",
    "remove_words = remove_stop_words + punctuations + double_quotes\n",
    "\n",
    "remove_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Words after Filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "['nlp', 'important', 'scientific', 'economic', 'social', 'cultural', 'reasons', 'nlp', 'experiencing', 'rapid', 'growth', 'theories', 'methods', 'deployed', 'variety', 'new', 'language', 'technologies', 'reason', 'important', 'wide', 'range', 'people', 'working', 'knowledge', 'nlp', 'within', 'industry', 'includes', 'people', 'human-computer', 'interaction', 'business', 'information', 'analysis', 'web', 'software', 'development', 'within', 'academia', 'includes', 'people', 'areas', 'humanities', 'computing', 'corpus', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'many', 'people', 'academia', 'nlp', 'known', 'name', 'computational', 'linguistics']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words = [\n",
    "    word\n",
    "    for word in words\n",
    "    if word not in remove_words\n",
    "]\n",
    "\n",
    "filtered_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Report the stop words found in the given text corpus. (6 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[('and', 5), ('is', 4), ('in', 4), ('of', 4), ('for', 3), ('a', 3), ('to', 3), ('this', 2), ('it', 2), ('as', 1), ('its', 1), ('are', 1), ('have', 1), ('from', 1), ('through', 1), ('by', 1), ('the', 1)]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_found = [\n",
    "    word\n",
    "    for word in words\n",
    "    if word in stop_words\n",
    "]\n",
    "\n",
    "freq_dist = nltk.FreqDist(stop_words_found)\n",
    "\n",
    "freq_dist.most_common()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'38 stop words found.'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{len(stop_words_found)} stop words found.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "f\"{len(freq_dist)} types of stop words found.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "'17 types of stop words found.'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q4. Form Parts of Speech (POS) Taggers & Syntactic Analysers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open, Read and Close Data_2 Textfile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'The little black dog barked at the white cat and chased away.'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file2 = \"data/Data_2.txt\"\n",
    "with open(file=data_file2) as f:\n",
    "    text2 = f.read()\n",
    "\n",
    "text2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Demonstrate POS tagging using NLTK POS tagger, textblob POS tagger and the Regular Expression tagger and report the output. (9 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-processing Text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "['the', 'little', 'black', 'dog', 'barked', 'at', 'the', 'white', 'cat', 'and', 'chased', 'away']"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations = string.punctuation\n",
    "words = [\n",
    "    word.lower()\n",
    "    for word in nltk.word_tokenize(text2)\n",
    "    if word not in punctuations\n",
    "]\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### POS Tagging using NLTK POS Tagger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[('the', 'DT'), ('little', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB')]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tokens = nltk.pos_tag(words)\n",
    "\n",
    "tagged_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### POS Tagging using TextBlob POS Tagger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[('the', 'DT'), ('little', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB')]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(text2.lower())\n",
    "tagged_tokens = blob.tags\n",
    "\n",
    "tagged_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### POS Tagging using Regular Expression Tagger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[('the', 'NN'), ('little', 'NN'), ('black', 'NN'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'NN'), ('the', 'NN'), ('white', 'NN'), ('cat', 'NN'), ('and', 'NN'), ('chased', 'VBD'), ('away', 'NN')]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),     # gerunds\n",
    "    (r'.*ed$', 'VBD'),      # simple past\n",
    "    (r'.*es$', 'VBZ'),      # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),     # modals\n",
    "    (r'.*\\'s$', 'NN$'),     # possessive nouns\n",
    "    (r'.*s$', 'NNS'),       # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*', 'NN'),          # nouns (default)\n",
    "    (r'^\\d+$', 'CD'),\n",
    "    (r'.*ing$', 'VBG'),     # gerunds, i.e. wondering\n",
    "    (r'.*ment$', 'NN'),     # i.e. wonderment\n",
    "    (r'.*ful$', 'JJ')       # i.e. wonderful\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "tagged_tokens = regexp_tagger.tag(words)\n",
    "\n",
    "tagged_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Draw possible parse trees for the given sentences using suitable python codes and report the Parse Trees along with the Python code. (5 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Det the) (NP (Nom (Adj little) (Adj black) (N dog))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (V barked))\n",
      "        (PP (P at) (NP (Det the) (NP (Nom (Adj white) (N cat))))))\n",
      "      (CC and)\n",
      "      (VP (V chased)))\n",
      "    (Adv away)))\n",
      "(S\n",
      "  (NP (Det the) (NP (Nom (Adj little) (Nom (Adj black) (N dog)))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (V barked))\n",
      "        (PP (P at) (NP (Det the) (NP (Nom (Adj white) (N cat))))))\n",
      "      (CC and)\n",
      "      (VP (V chased)))\n",
      "    (Adv away)))\n",
      "(S\n",
      "  (NP (Det the) (NP (Nom (Adj little) (Adj black) (N dog))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V barked))\n",
      "      (PP (P at) (NP (Det the) (NP (Nom (Adj white) (N cat))))))\n",
      "    (CC and)\n",
      "    (VP (VP (V chased)) (Adv away))))\n",
      "(S\n",
      "  (NP (Det the) (NP (Nom (Adj little) (Nom (Adj black) (N dog)))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V barked))\n",
      "      (PP (P at) (NP (Det the) (NP (Nom (Adj white) (N cat))))))\n",
      "    (CC and)\n",
      "    (VP (VP (V chased)) (Adv away))))\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"S -> S CC S | NP VP\",\n",
    "    \"VP -> VP CC VP | VP NP | VP Adv | VP PP | V\",\n",
    "    \"NP -> NP CC NP | NP PP | Det NP | Nom | N\",\n",
    "    \"PP -> P NP\",\n",
    "    \"Nom -> Adj Nom | Adj Adj N | Adj N\",\n",
    "    \"N -> N CC N | 'dog' | 'cat'\",\n",
    "    \"V -> 'barked' | 'chased'\",\n",
    "    \"Adj -> 'little' | 'black' | 'white'\",\n",
    "    \"P -> 'at'\",\n",
    "    \"CC -> 'and'\",\n",
    "    \"Adv -> 'away'\",\n",
    "    \"Det -> 'the'\",\n",
    "]\n",
    "grammar = nltk.CFG.fromstring(inputs)\n",
    "\n",
    "chart_parser = nltk.ChartParser(grammar=grammar)\n",
    "trees = chart_parser.parse(words)\n",
    "for tree in trees:\n",
    "    tree.draw()\n",
    "    print(tree)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print documentation of a tag"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VBG')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Det the) (NP (Nom (Adj cute) (Adj white) (N cat))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (V starred))\n",
      "        (PP (P at) (NP (Det the) (NP (Nom (Adj black) (N rat))))))\n",
      "      (CC and)\n",
      "      (VP (V chased)))\n",
      "    (Adv away)))\n",
      "(S\n",
      "  (NP (Det the) (NP (Nom (Adj cute) (Nom (Adj white) (N cat)))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (V starred))\n",
      "        (PP (P at) (NP (Det the) (NP (Nom (Adj black) (N rat))))))\n",
      "      (CC and)\n",
      "      (VP (V chased)))\n",
      "    (Adv away)))\n",
      "(S\n",
      "  (NP (Det the) (NP (Nom (Adj cute) (Adj white) (N cat))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V starred))\n",
      "      (PP (P at) (NP (Det the) (NP (Nom (Adj black) (N rat))))))\n",
      "    (CC and)\n",
      "    (VP (VP (V chased)) (Adv away))))\n",
      "(S\n",
      "  (NP (Det the) (NP (Nom (Adj cute) (Nom (Adj white) (N cat)))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V starred))\n",
      "      (PP (P at) (NP (Det the) (NP (Nom (Adj black) (N rat))))))\n",
      "    (CC and)\n",
      "    (VP (VP (V chased)) (Adv away))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = \"The cute white cat starred at the black rat and chased away.\"\n",
    "text = text.replace(\".\", \"\")\n",
    "words = nltk.word_tokenize(text.lower())\n",
    "inputs = [\n",
    "    \"S -> S CC S | NP VP\",\n",
    "    \"VP -> VP CC VP | VP NP | VP Adv | VP PP | V\",\n",
    "    \"NP -> NP CC NP | NP PP | Det NP | Nom | N\",\n",
    "    \"PP -> P NP\",\n",
    "    \"Nom -> Adj Nom | Adj Adj N | Adj N\",\n",
    "    \"N -> N CC N | 'cat' | 'rat'\",\n",
    "    \"V -> 'starred' | 'chased'\",\n",
    "    \"Adj -> 'cute' | 'white' | 'black'\",\n",
    "    \"P -> 'at'\",\n",
    "    \"CC -> 'and'\",\n",
    "    \"Adv -> 'away'\",\n",
    "    \"Det -> 'the'\",\n",
    "]\n",
    "grammar = nltk.CFG.fromstring(inputs)\n",
    "\n",
    "chart_parser = nltk.ChartParser(grammar=grammar)\n",
    "trees = chart_parser.parse(words)\n",
    "for tree in trees:\n",
    "    tree.draw()\n",
    "    print(tree)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}