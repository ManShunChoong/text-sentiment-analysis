{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Open, Read and Close Textfile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'NLP is important for scientific, economic, social, and cultural reasons. NLP is experiencing rapid growth as its theories and methods are deployed in a variety of new language technologies. For this reason it is important for a wide range of people to have a working knowledge of NLP. Within industry, this includes people in human-computer interaction, business information analysis, and web software development. Within academia, it includes people in areas from humanities computing and corpus linguistics through to computer science and artificial intelligence. (To many people in academia, NLP is known by the name of \"Computational Linguistics.\")'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file1 = \"data/Data_1.txt\"\n",
    "with open(file=data_file1) as f:\n",
    "    text = f.read()\n",
    "\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q1. Form Tokenisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Demonstrate sentence segmentation and report the output. (6 marks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Segmentation using Split Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP is important for scientific, economic, social, and cultural reasons',\n 'NLP is experiencing rapid growth as its theories and methods are deployed in a variety of new language technologies',\n 'For this reason it is important for a wide range of people to have a working knowledge of NLP',\n 'Within industry, this includes people in human-computer interaction, business information analysis, and web software development',\n 'Within academia, it includes people in areas from humanities computing and corpus linguistics through to computer science and artificial intelligence',\n '(To many people in academia, NLP is known by the name of \"Computational Linguistics.\")']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = text.split(\". \")\n",
    "\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Segmentation using Regular Expression Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP is important for scientific, economic, social, and cultural reasons',\n 'NLP is experiencing rapid growth as its theories and methods are deployed in a variety of new language technologies',\n 'For this reason it is important for a wide range of people to have a working knowledge of NLP',\n 'Within industry, this includes people in human-computer interaction, business information analysis, and web software development',\n 'Within academia, it includes people in areas from humanities computing and corpus linguistics through to computer science and artificial intelligence',\n '(To many people in academia, NLP is known by the name of \"Computational Linguistics.\")']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentences = re.split(r\"[.!?] \", text)\n",
    "\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Segmentation using NLTK Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP is important for scientific, economic, social, and cultural reasons.',\n 'NLP is experiencing rapid growth as its theories and methods are deployed in a variety of new language technologies.',\n 'For this reason it is important for a wide range of people to have a working knowledge of NLP.',\n 'Within industry, this includes people in human-computer interaction, business information analysis, and web software development.',\n 'Within academia, it includes people in areas from humanities computing and corpus linguistics through to computer science and artificial intelligence.',\n '(To many people in academia, NLP is known by the name of \"Computational Linguistics.\")']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Demonstrate word tokenisation using the split function, Regular Expression and NLTK packages separately and report the output. (10 marks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Tokenisation using Split Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP',\n 'is',\n 'important',\n 'for',\n 'scientific,',\n 'economic,',\n 'social,',\n 'and',\n 'cultural',\n 'reasons.',\n 'NLP',\n 'is',\n 'experiencing',\n 'rapid',\n 'growth',\n 'as',\n 'its',\n 'theories',\n 'and',\n 'methods',\n 'are',\n 'deployed',\n 'in',\n 'a',\n 'variety',\n 'of',\n 'new',\n 'language',\n 'technologies.',\n 'For',\n 'this',\n 'reason',\n 'it',\n 'is',\n 'important',\n 'for',\n 'a',\n 'wide',\n 'range',\n 'of',\n 'people',\n 'to',\n 'have',\n 'a',\n 'working',\n 'knowledge',\n 'of',\n 'NLP.',\n 'Within',\n 'industry,',\n 'this',\n 'includes',\n 'people',\n 'in',\n 'human-computer',\n 'interaction,',\n 'business',\n 'information',\n 'analysis,',\n 'and',\n 'web',\n 'software',\n 'development.',\n 'Within',\n 'academia,',\n 'it',\n 'includes',\n 'people',\n 'in',\n 'areas',\n 'from',\n 'humanities',\n 'computing',\n 'and',\n 'corpus',\n 'linguistics',\n 'through',\n 'to',\n 'computer',\n 'science',\n 'and',\n 'artificial',\n 'intelligence.',\n '(To',\n 'many',\n 'people',\n 'in',\n 'academia,',\n 'NLP',\n 'is',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n '\"Computational',\n 'Linguistics.\")']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split()\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Tokenisation using Regular Expression Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP',\n 'is',\n 'important',\n 'for',\n 'scientific,',\n 'economic,',\n 'social,',\n 'and',\n 'cultural',\n 'reasons.',\n 'NLP',\n 'is',\n 'experiencing',\n 'rapid',\n 'growth',\n 'as',\n 'its',\n 'theories',\n 'and',\n 'methods',\n 'are',\n 'deployed',\n 'in',\n 'a',\n 'variety',\n 'of',\n 'new',\n 'language',\n 'technologies.',\n 'For',\n 'this',\n 'reason',\n 'it',\n 'is',\n 'important',\n 'for',\n 'a',\n 'wide',\n 'range',\n 'of',\n 'people',\n 'to',\n 'have',\n 'a',\n 'working',\n 'knowledge',\n 'of',\n 'NLP.',\n 'Within',\n 'industry,',\n 'this',\n 'includes',\n 'people',\n 'in',\n 'human-computer',\n 'interaction,',\n 'business',\n 'information',\n 'analysis,',\n 'and',\n 'web',\n 'software',\n 'development.',\n 'Within',\n 'academia,',\n 'it',\n 'includes',\n 'people',\n 'in',\n 'areas',\n 'from',\n 'humanities',\n 'computing',\n 'and',\n 'corpus',\n 'linguistics',\n 'through',\n 'to',\n 'computer',\n 'science',\n 'and',\n 'artificial',\n 'intelligence.',\n '(To',\n 'many',\n 'people',\n 'in',\n 'academia,',\n 'NLP',\n 'is',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n '\"Computational',\n 'Linguistics.\")']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = re.split(r\" \", text)\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP',\n 'is',\n 'important',\n 'for',\n 'scientific',\n 'economic',\n 'social',\n 'and',\n 'cultural',\n 'reasons',\n 'NLP',\n 'is',\n 'experiencing',\n 'rapid',\n 'growth',\n 'as',\n 'its',\n 'theories',\n 'and',\n 'methods',\n 'are',\n 'deployed',\n 'in',\n 'a',\n 'variety',\n 'of',\n 'new',\n 'language',\n 'technologies',\n 'For',\n 'this',\n 'reason',\n 'it',\n 'is',\n 'important',\n 'for',\n 'a',\n 'wide',\n 'range',\n 'of',\n 'people',\n 'to',\n 'have',\n 'a',\n 'working',\n 'knowledge',\n 'of',\n 'NLP',\n 'Within',\n 'industry',\n 'this',\n 'includes',\n 'people',\n 'in',\n 'human',\n 'computer',\n 'interaction',\n 'business',\n 'information',\n 'analysis',\n 'and',\n 'web',\n 'software',\n 'development',\n 'Within',\n 'academia',\n 'it',\n 'includes',\n 'people',\n 'in',\n 'areas',\n 'from',\n 'humanities',\n 'computing',\n 'and',\n 'corpus',\n 'linguistics',\n 'through',\n 'to',\n 'computer',\n 'science',\n 'and',\n 'artificial',\n 'intelligence',\n 'To',\n 'many',\n 'people',\n 'in',\n 'academia',\n 'NLP',\n 'is',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n 'Computational',\n 'Linguistics',\n '']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = re.split(r\"\\W+\", text)\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Tokenisation using NLTK Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP',\n 'is',\n 'important',\n 'for',\n 'scientific',\n ',',\n 'economic',\n ',',\n 'social',\n ',',\n 'and',\n 'cultural',\n 'reasons',\n '.',\n 'NLP',\n 'is',\n 'experiencing',\n 'rapid',\n 'growth',\n 'as',\n 'its',\n 'theories',\n 'and',\n 'methods',\n 'are',\n 'deployed',\n 'in',\n 'a',\n 'variety',\n 'of',\n 'new',\n 'language',\n 'technologies',\n '.',\n 'For',\n 'this',\n 'reason',\n 'it',\n 'is',\n 'important',\n 'for',\n 'a',\n 'wide',\n 'range',\n 'of',\n 'people',\n 'to',\n 'have',\n 'a',\n 'working',\n 'knowledge',\n 'of',\n 'NLP',\n '.',\n 'Within',\n 'industry',\n ',',\n 'this',\n 'includes',\n 'people',\n 'in',\n 'human-computer',\n 'interaction',\n ',',\n 'business',\n 'information',\n 'analysis',\n ',',\n 'and',\n 'web',\n 'software',\n 'development',\n '.',\n 'Within',\n 'academia',\n ',',\n 'it',\n 'includes',\n 'people',\n 'in',\n 'areas',\n 'from',\n 'humanities',\n 'computing',\n 'and',\n 'corpus',\n 'linguistics',\n 'through',\n 'to',\n 'computer',\n 'science',\n 'and',\n 'artificial',\n 'intelligence',\n '.',\n '(',\n 'To',\n 'many',\n 'people',\n 'in',\n 'academia',\n ',',\n 'NLP',\n 'is',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n '``',\n 'Computational',\n 'Linguistics',\n '.',\n \"''\",\n ')']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Tokenisation using TextBlob Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "WordList(['NLP', 'is', 'important', 'for', 'scientific', 'economic', 'social', 'and', 'cultural', 'reasons', 'NLP', 'is', 'experiencing', 'rapid', 'growth', 'as', 'its', 'theories', 'and', 'methods', 'are', 'deployed', 'in', 'a', 'variety', 'of', 'new', 'language', 'technologies', 'For', 'this', 'reason', 'it', 'is', 'important', 'for', 'a', 'wide', 'range', 'of', 'people', 'to', 'have', 'a', 'working', 'knowledge', 'of', 'NLP', 'Within', 'industry', 'this', 'includes', 'people', 'in', 'human-computer', 'interaction', 'business', 'information', 'analysis', 'and', 'web', 'software', 'development', 'Within', 'academia', 'it', 'includes', 'people', 'in', 'areas', 'from', 'humanities', 'computing', 'and', 'corpus', 'linguistics', 'through', 'to', 'computer', 'science', 'and', 'artificial', 'intelligence', 'To', 'many', 'people', 'in', 'academia', 'NLP', 'is', 'known', 'by', 'the', 'name', 'of', 'Computational', 'Linguistics'])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(text)\n",
    "words = blob.words\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q2. Form Word Stemming"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Demonstrate word stemming using Regular Expression, Porter Stemmer and Lancaster Stemmer and report the output. (12 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Basic Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP',\n 'i',\n 'important',\n 'for',\n 'scientific',\n ',',\n 'economic',\n ',',\n 'social',\n ',',\n 'and',\n 'cultural',\n 'reason',\n '.',\n 'NLP',\n 'i',\n 'experienc',\n 'rapid',\n 'growth',\n 'a',\n 'it',\n 'theor',\n 'and',\n 'method',\n 'are',\n 'deploy',\n 'in',\n 'a',\n 'variety',\n 'of',\n 'new',\n 'language',\n 'technolog',\n '.',\n 'For',\n 'thi',\n 'reason',\n 'it',\n 'i',\n 'important',\n 'for',\n 'a',\n 'wide',\n 'range',\n 'of',\n 'people',\n 'to',\n 'have',\n 'a',\n 'work',\n 'knowledge',\n 'of',\n 'NLP',\n '.',\n 'Within',\n 'industry',\n ',',\n 'thi',\n 'includ',\n 'people',\n 'in',\n 'human-computer',\n 'interaction',\n ',',\n 'busines',\n 'information',\n 'analysi',\n ',',\n 'and',\n 'web',\n 'software',\n 'develop',\n '.',\n 'Within',\n 'academia',\n ',',\n 'it',\n 'includ',\n 'people',\n 'in',\n 'area',\n 'from',\n 'humanit',\n 'comput',\n 'and',\n 'corpu',\n 'linguistic',\n 'through',\n 'to',\n 'computer',\n 'science',\n 'and',\n 'artificial',\n 'intelligence',\n '.',\n '(',\n 'To',\n 'many',\n 'people',\n 'in',\n 'academia',\n ',',\n 'NLP',\n 'i',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n '``',\n 'Computational',\n 'Linguistic',\n '.',\n \"''\",\n ')']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffixes = [\"ing\", \"ly\", \"ed\", \"ious\", \"ies\", \"ive\", \"es\", \"s\", \"ment\"]\n",
    "\n",
    "def stem(word):\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "stemmed_words = [stem(word)for word in words]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Regular Expression Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP',\n 'i',\n 'important',\n 'for',\n 'scientific',\n ',',\n 'economic',\n ',',\n 'social',\n ',',\n 'and',\n 'cultural',\n 'reason',\n '.',\n 'NLP',\n 'i',\n 'experienc',\n 'rapid',\n 'growth',\n 'a',\n 'it',\n 'theor',\n 'and',\n 'method',\n 'are',\n 'deploy',\n 'in',\n 'a',\n 'variety',\n 'of',\n 'new',\n 'language',\n 'technolog',\n '.',\n 'For',\n 'thi',\n 'reason',\n 'it',\n 'i',\n 'important',\n 'for',\n 'a',\n 'wide',\n 'range',\n 'of',\n 'people',\n 'to',\n 'have',\n 'a',\n 'work',\n 'knowledge',\n 'of',\n 'NLP',\n '.',\n 'Within',\n 'industry',\n ',',\n 'thi',\n 'includ',\n 'people',\n 'in',\n 'human-computer',\n 'interaction',\n ',',\n 'busines',\n 'information',\n 'analysi',\n ',',\n 'and',\n 'web',\n 'software',\n 'develop',\n '.',\n 'Within',\n 'academia',\n ',',\n 'it',\n 'includ',\n 'people',\n 'in',\n 'area',\n 'from',\n 'humanit',\n 'comput',\n 'and',\n 'corpu',\n 'linguistic',\n 'through',\n 'to',\n 'computer',\n 'science',\n 'and',\n 'artificial',\n 'intelligence',\n '.',\n '(',\n 'To',\n 'many',\n 'people',\n 'in',\n 'academia',\n ',',\n 'NLP',\n 'i',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n '``',\n 'Computational',\n 'Linguistic',\n '.',\n \"''\",\n ')']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_stem_pattern = r\"^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$\"\n",
    "stemmed_words = [\n",
    "    re.findall(split_stem_pattern, word)[0][0]\n",
    "    for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Porter Stemmer Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['nlp',\n 'is',\n 'import',\n 'for',\n 'scientif',\n ',',\n 'econom',\n ',',\n 'social',\n ',',\n 'and',\n 'cultur',\n 'reason',\n '.',\n 'nlp',\n 'is',\n 'experienc',\n 'rapid',\n 'growth',\n 'as',\n 'it',\n 'theori',\n 'and',\n 'method',\n 'are',\n 'deploy',\n 'in',\n 'a',\n 'varieti',\n 'of',\n 'new',\n 'languag',\n 'technolog',\n '.',\n 'for',\n 'thi',\n 'reason',\n 'it',\n 'is',\n 'import',\n 'for',\n 'a',\n 'wide',\n 'rang',\n 'of',\n 'peopl',\n 'to',\n 'have',\n 'a',\n 'work',\n 'knowledg',\n 'of',\n 'nlp',\n '.',\n 'within',\n 'industri',\n ',',\n 'thi',\n 'includ',\n 'peopl',\n 'in',\n 'human-comput',\n 'interact',\n ',',\n 'busi',\n 'inform',\n 'analysi',\n ',',\n 'and',\n 'web',\n 'softwar',\n 'develop',\n '.',\n 'within',\n 'academia',\n ',',\n 'it',\n 'includ',\n 'peopl',\n 'in',\n 'area',\n 'from',\n 'human',\n 'comput',\n 'and',\n 'corpu',\n 'linguist',\n 'through',\n 'to',\n 'comput',\n 'scienc',\n 'and',\n 'artifici',\n 'intellig',\n '.',\n '(',\n 'to',\n 'mani',\n 'peopl',\n 'in',\n 'academia',\n ',',\n 'nlp',\n 'is',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n '``',\n 'comput',\n 'linguist',\n '.',\n \"''\",\n ')']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster_stemmer = nltk.PorterStemmer()\n",
    "stemmed_words = [\n",
    "    lancaster_stemmer.stem(word) for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Lancaster Stemmer Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['nlp',\n 'is',\n 'import',\n 'for',\n 'sci',\n ',',\n 'econom',\n ',',\n 'soc',\n ',',\n 'and',\n 'cult',\n 'reason',\n '.',\n 'nlp',\n 'is',\n 'expery',\n 'rapid',\n 'grow',\n 'as',\n 'it',\n 'the',\n 'and',\n 'method',\n 'ar',\n 'deploy',\n 'in',\n 'a',\n 'vary',\n 'of',\n 'new',\n 'langu',\n 'technolog',\n '.',\n 'for',\n 'thi',\n 'reason',\n 'it',\n 'is',\n 'import',\n 'for',\n 'a',\n 'wid',\n 'rang',\n 'of',\n 'peopl',\n 'to',\n 'hav',\n 'a',\n 'work',\n 'knowledg',\n 'of',\n 'nlp',\n '.',\n 'within',\n 'industry',\n ',',\n 'thi',\n 'includ',\n 'peopl',\n 'in',\n 'human-computer',\n 'interact',\n ',',\n 'busy',\n 'inform',\n 'analys',\n ',',\n 'and',\n 'web',\n 'softw',\n 'develop',\n '.',\n 'within',\n 'academ',\n ',',\n 'it',\n 'includ',\n 'peopl',\n 'in',\n 'area',\n 'from',\n 'hum',\n 'comput',\n 'and',\n 'corp',\n 'lingu',\n 'through',\n 'to',\n 'comput',\n 'sci',\n 'and',\n 'art',\n 'intellig',\n '.',\n '(',\n 'to',\n 'many',\n 'peopl',\n 'in',\n 'academ',\n ',',\n 'nlp',\n 'is',\n 'known',\n 'by',\n 'the',\n 'nam',\n 'of',\n '``',\n 'comput',\n 'lingu',\n '.',\n \"''\",\n ')']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster_stemmer = nltk.LancasterStemmer()\n",
    "stemmed_words = [\n",
    "    lancaster_stemmer.stem(word) for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Stemming using Snowball Stemmer Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['nlp',\n 'is',\n 'import',\n 'for',\n 'scientif',\n ',',\n 'econom',\n ',',\n 'social',\n ',',\n 'and',\n 'cultur',\n 'reason',\n '.',\n 'nlp',\n 'is',\n 'experienc',\n 'rapid',\n 'growth',\n 'as',\n 'it',\n 'theori',\n 'and',\n 'method',\n 'are',\n 'deploy',\n 'in',\n 'a',\n 'varieti',\n 'of',\n 'new',\n 'languag',\n 'technolog',\n '.',\n 'for',\n 'this',\n 'reason',\n 'it',\n 'is',\n 'import',\n 'for',\n 'a',\n 'wide',\n 'rang',\n 'of',\n 'peopl',\n 'to',\n 'have',\n 'a',\n 'work',\n 'knowledg',\n 'of',\n 'nlp',\n '.',\n 'within',\n 'industri',\n ',',\n 'this',\n 'includ',\n 'peopl',\n 'in',\n 'human-comput',\n 'interact',\n ',',\n 'busi',\n 'inform',\n 'analysi',\n ',',\n 'and',\n 'web',\n 'softwar',\n 'develop',\n '.',\n 'within',\n 'academia',\n ',',\n 'it',\n 'includ',\n 'peopl',\n 'in',\n 'area',\n 'from',\n 'human',\n 'comput',\n 'and',\n 'corpus',\n 'linguist',\n 'through',\n 'to',\n 'comput',\n 'scienc',\n 'and',\n 'artifici',\n 'intellig',\n '.',\n '(',\n 'to',\n 'mani',\n 'peopl',\n 'in',\n 'academia',\n ',',\n 'nlp',\n 'is',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n '``',\n 'comput',\n 'linguist',\n '.',\n \"''\",\n ')']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer = nltk.SnowballStemmer(language=\"english\")\n",
    "stemmed_words = [\n",
    "    snowball_stemmer.stem(word) for word in words\n",
    "]\n",
    "\n",
    "stemmed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q3. Filter Stop Words and Punctuation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Demonstrate stop words and punctuations removal from the given text corpus and report the output suitably. (12 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Words before Filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP',\n 'is',\n 'important',\n 'for',\n 'scientific',\n ',',\n 'economic',\n ',',\n 'social',\n ',',\n 'and',\n 'cultural',\n 'reasons',\n '.',\n 'NLP',\n 'is',\n 'experiencing',\n 'rapid',\n 'growth',\n 'as',\n 'its',\n 'theories',\n 'and',\n 'methods',\n 'are',\n 'deployed',\n 'in',\n 'a',\n 'variety',\n 'of',\n 'new',\n 'language',\n 'technologies',\n '.',\n 'For',\n 'this',\n 'reason',\n 'it',\n 'is',\n 'important',\n 'for',\n 'a',\n 'wide',\n 'range',\n 'of',\n 'people',\n 'to',\n 'have',\n 'a',\n 'working',\n 'knowledge',\n 'of',\n 'NLP',\n '.',\n 'Within',\n 'industry',\n ',',\n 'this',\n 'includes',\n 'people',\n 'in',\n 'human-computer',\n 'interaction',\n ',',\n 'business',\n 'information',\n 'analysis',\n ',',\n 'and',\n 'web',\n 'software',\n 'development',\n '.',\n 'Within',\n 'academia',\n ',',\n 'it',\n 'includes',\n 'people',\n 'in',\n 'areas',\n 'from',\n 'humanities',\n 'computing',\n 'and',\n 'corpus',\n 'linguistics',\n 'through',\n 'to',\n 'computer',\n 'science',\n 'and',\n 'artificial',\n 'intelligence',\n '.',\n '(',\n 'To',\n 'many',\n 'people',\n 'in',\n 'academia',\n ',',\n 'NLP',\n 'is',\n 'known',\n 'by',\n 'the',\n 'name',\n 'of',\n '``',\n 'Computational',\n 'Linguistics',\n '.',\n \"''\",\n ')']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Words after Filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['NLP',\n 'important',\n 'scientific',\n 'economic',\n 'social',\n 'cultural',\n 'reasons',\n 'NLP',\n 'experiencing',\n 'rapid',\n 'growth',\n 'theories',\n 'methods',\n 'deployed',\n 'variety',\n 'new',\n 'language',\n 'technologies',\n 'For',\n 'reason',\n 'important',\n 'wide',\n 'range',\n 'people',\n 'working',\n 'knowledge',\n 'NLP',\n 'Within',\n 'industry',\n 'includes',\n 'people',\n 'human-computer',\n 'interaction',\n 'business',\n 'information',\n 'analysis',\n 'web',\n 'software',\n 'development',\n 'Within',\n 'academia',\n 'includes',\n 'people',\n 'areas',\n 'humanities',\n 'computing',\n 'corpus',\n 'linguistics',\n 'computer',\n 'science',\n 'artificial',\n 'intelligence',\n 'To',\n 'many',\n 'people',\n 'academia',\n 'NLP',\n 'known',\n 'name',\n 'Computational',\n 'Linguistics']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "punctuations = list(string.punctuation) + [\"``\", \"''\"]\n",
    "\n",
    "filtered_words = [\n",
    "    word\n",
    "    for word in words\n",
    "    if word not in stop_words and word not in punctuations\n",
    "]\n",
    "\n",
    "filtered_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stop Words Found"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['it',\n 'its',\n 'this',\n 'is',\n 'are',\n 'have',\n 'a',\n 'the',\n 'and',\n 'as',\n 'of',\n 'by',\n 'for',\n 'through',\n 'to',\n 'from',\n 'in']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_found = [\n",
    "    word\n",
    "    for word in stop_words\n",
    "    if word in words\n",
    "]\n",
    "\n",
    "stop_words_found"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q4. Form Parts of Speech (POS) Taggers & Syntactic Analysers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Demonstrate POS tagging using NLTK POS tagger, textblob POS tagger and the Regular Expression tagger and report the output. (9 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "punctuations = list(string.punctuation) + [\"``\", \"''\"]\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "word_tokenized_sentences = [\n",
    "    [\n",
    "        word.lower()\n",
    "        for word in nltk.word_tokenize(sentence)\n",
    "        if word not in punctuations\n",
    "    ]\n",
    "    for sentence in sentences\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### POS Tagging using NLTK POS Tagger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "[('nlp', 'NN'), ('is', 'VBZ'), ('important', 'JJ'), ('for', 'IN'), ('scientific', 'JJ'), ('economic', 'JJ'), ('social', 'JJ'), ('and', 'CC'), ('cultural', 'JJ'), ('reasons', 'NNS')]\n",
      "\n",
      "Sentence 2:\n",
      "[('nlp', 'NN'), ('is', 'VBZ'), ('experiencing', 'VBG'), ('rapid', 'JJ'), ('growth', 'NN'), ('as', 'IN'), ('its', 'PRP$'), ('theories', 'NNS'), ('and', 'CC'), ('methods', 'NNS'), ('are', 'VBP'), ('deployed', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('variety', 'NN'), ('of', 'IN'), ('new', 'JJ'), ('language', 'NN'), ('technologies', 'NNS')]\n",
      "\n",
      "Sentence 3:\n",
      "[('for', 'IN'), ('this', 'DT'), ('reason', 'NN'), ('it', 'PRP'), ('is', 'VBZ'), ('important', 'JJ'), ('for', 'IN'), ('a', 'DT'), ('wide', 'JJ'), ('range', 'NN'), ('of', 'IN'), ('people', 'NNS'), ('to', 'TO'), ('have', 'VB'), ('a', 'DT'), ('working', 'JJ'), ('knowledge', 'NN'), ('of', 'IN'), ('nlp', 'NN')]\n",
      "\n",
      "Sentence 4:\n",
      "[('within', 'IN'), ('industry', 'NN'), ('this', 'DT'), ('includes', 'VBZ'), ('people', 'NNS'), ('in', 'IN'), ('human-computer', 'JJ'), ('interaction', 'NN'), ('business', 'NN'), ('information', 'NN'), ('analysis', 'NN'), ('and', 'CC'), ('web', 'NN'), ('software', 'NN'), ('development', 'NN')]\n",
      "\n",
      "Sentence 5:\n",
      "[('within', 'IN'), ('academia', 'NN'), ('it', 'PRP'), ('includes', 'VBZ'), ('people', 'NNS'), ('in', 'IN'), ('areas', 'NNS'), ('from', 'IN'), ('humanities', 'NNS'), ('computing', 'VBG'), ('and', 'CC'), ('corpus', 'NN'), ('linguistics', 'NNS'), ('through', 'IN'), ('to', 'TO'), ('computer', 'NN'), ('science', 'NN'), ('and', 'CC'), ('artificial', 'JJ'), ('intelligence', 'NN')]\n",
      "\n",
      "Sentence 6:\n",
      "[('to', 'TO'), ('many', 'JJ'), ('people', 'NNS'), ('in', 'IN'), ('academia', 'NN'), ('nlp', 'NN'), ('is', 'VBZ'), ('known', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('name', 'NN'), ('of', 'IN'), ('computational', 'JJ'), ('linguistics', 'NNS')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(word_tokenized_sentences):\n",
    "    tagged_tokens = nltk.pos_tag(sentence)\n",
    "    print(f\"Sentence {index + 1}:\\n{tagged_tokens}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### POS Tagging using TextBlob POS Tagger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "[('NLP', 'NNP'), ('is', 'VBZ'), ('important', 'JJ'), ('for', 'IN'), ('scientific', 'JJ'), ('economic', 'JJ'), ('social', 'JJ'), ('and', 'CC'), ('cultural', 'JJ'), ('reasons', 'NNS')]\n",
      "\n",
      "Sentence 2:\n",
      "[('NLP', 'NNP'), ('is', 'VBZ'), ('experiencing', 'VBG'), ('rapid', 'JJ'), ('growth', 'NN'), ('as', 'IN'), ('its', 'PRP$'), ('theories', 'NNS'), ('and', 'CC'), ('methods', 'NNS'), ('are', 'VBP'), ('deployed', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('variety', 'NN'), ('of', 'IN'), ('new', 'JJ'), ('language', 'NN'), ('technologies', 'NNS')]\n",
      "\n",
      "Sentence 3:\n",
      "[('For', 'IN'), ('this', 'DT'), ('reason', 'NN'), ('it', 'PRP'), ('is', 'VBZ'), ('important', 'JJ'), ('for', 'IN'), ('a', 'DT'), ('wide', 'JJ'), ('range', 'NN'), ('of', 'IN'), ('people', 'NNS'), ('to', 'TO'), ('have', 'VB'), ('a', 'DT'), ('working', 'JJ'), ('knowledge', 'NN'), ('of', 'IN'), ('NLP', 'NNP')]\n",
      "\n",
      "Sentence 4:\n",
      "[('Within', 'IN'), ('industry', 'NN'), ('this', 'DT'), ('includes', 'VBZ'), ('people', 'NNS'), ('in', 'IN'), ('human-computer', 'JJ'), ('interaction', 'NN'), ('business', 'NN'), ('information', 'NN'), ('analysis', 'NN'), ('and', 'CC'), ('web', 'JJS'), ('software', 'NN'), ('development', 'NN')]\n",
      "\n",
      "Sentence 5:\n",
      "[('Within', 'IN'), ('academia', 'NN'), ('it', 'PRP'), ('includes', 'VBZ'), ('people', 'NNS'), ('in', 'IN'), ('areas', 'NNS'), ('from', 'IN'), ('humanities', 'NNS'), ('computing', 'VBG'), ('and', 'CC'), ('corpus', 'NN'), ('linguistics', 'NNS'), ('through', 'IN'), ('to', 'TO'), ('computer', 'NN'), ('science', 'NN'), ('and', 'CC'), ('artificial', 'JJ'), ('intelligence', 'NN')]\n",
      "\n",
      "Sentence 6:\n",
      "[('To', 'TO'), ('many', 'JJ'), ('people', 'NNS'), ('in', 'IN'), ('academia', 'NN'), ('NLP', 'NNP'), ('is', 'VBZ'), ('known', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('name', 'NN'), ('of', 'IN'), ('Computational', 'JJ'), ('Linguistics', 'NNPS')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(sentences):\n",
    "    blob = TextBlob(sentence)\n",
    "    tagged_tokens = blob.tags\n",
    "    print(f\"Sentence {index + 1}:\\n{tagged_tokens}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### POS Tagging using Regular Expression Tagger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "[('nlp', 'NN'), ('is', 'NNS'), ('important', 'NN'), ('for', 'NN'), ('scientific', 'NN'), ('economic', 'NN'), ('social', 'NN'), ('and', 'NN'), ('cultural', 'NN'), ('reasons', 'NNS')]\n",
      "\n",
      "Sentence 2:\n",
      "[('nlp', 'NN'), ('is', 'NNS'), ('experiencing', 'VBG'), ('rapid', 'NN'), ('growth', 'NN'), ('as', 'NNS'), ('its', 'NNS'), ('theories', 'VBZ'), ('and', 'NN'), ('methods', 'NNS'), ('are', 'NN'), ('deployed', 'VBD'), ('in', 'NN'), ('a', 'NN'), ('variety', 'NN'), ('of', 'NN'), ('new', 'NN'), ('language', 'NN'), ('technologies', 'VBZ')]\n",
      "\n",
      "Sentence 3:\n",
      "[('for', 'NN'), ('this', 'NNS'), ('reason', 'NN'), ('it', 'NN'), ('is', 'NNS'), ('important', 'NN'), ('for', 'NN'), ('a', 'NN'), ('wide', 'NN'), ('range', 'NN'), ('of', 'NN'), ('people', 'NN'), ('to', 'NN'), ('have', 'NN'), ('a', 'NN'), ('working', 'VBG'), ('knowledge', 'NN'), ('of', 'NN'), ('nlp', 'NN')]\n",
      "\n",
      "Sentence 4:\n",
      "[('within', 'NN'), ('industry', 'NN'), ('this', 'NNS'), ('includes', 'VBZ'), ('people', 'NN'), ('in', 'NN'), ('human-computer', 'NN'), ('interaction', 'NN'), ('business', 'NNS'), ('information', 'NN'), ('analysis', 'NNS'), ('and', 'NN'), ('web', 'NN'), ('software', 'NN'), ('development', 'NN')]\n",
      "\n",
      "Sentence 5:\n",
      "[('within', 'NN'), ('academia', 'NN'), ('it', 'NN'), ('includes', 'VBZ'), ('people', 'NN'), ('in', 'NN'), ('areas', 'NNS'), ('from', 'NN'), ('humanities', 'VBZ'), ('computing', 'VBG'), ('and', 'NN'), ('corpus', 'NNS'), ('linguistics', 'NNS'), ('through', 'NN'), ('to', 'NN'), ('computer', 'NN'), ('science', 'NN'), ('and', 'NN'), ('artificial', 'NN'), ('intelligence', 'NN')]\n",
      "\n",
      "Sentence 6:\n",
      "[('to', 'NN'), ('many', 'NN'), ('people', 'NN'), ('in', 'NN'), ('academia', 'NN'), ('nlp', 'NN'), ('is', 'NNS'), ('known', 'NN'), ('by', 'NN'), ('the', 'NN'), ('name', 'NN'), ('of', 'NN'), ('computational', 'NN'), ('linguistics', 'NNS')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),     # gerunds\n",
    "    (r'.*ed$', 'VBD'),      # simple past\n",
    "    (r'.*es$', 'VBZ'),      # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),     # modals\n",
    "    (r'.*\\'s$', 'NN$'),     # possessive nouns\n",
    "    (r'.*s$', 'NNS'),       # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*', 'NN'),          # nouns (default)\n",
    "    (r'^\\d+$', 'CD'),\n",
    "    (r'.*ing$', 'VBG'),     # gerunds, i.e. wondering\n",
    "    (r'.*ment$', 'NN'),     # i.e. wonderment\n",
    "    (r'.*ful$', 'JJ')       # i.e. wonderful\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "for index, sentence in enumerate(word_tokenized_sentences):\n",
    "    tagged_tokens = regexp_tagger.tag(sentence)\n",
    "    print(f\"Sentence {index + 1}:\\n{tagged_tokens}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Draw possible parse trees for the given sentences using suitable python codes and report the Parse Trees along with the Python code. (5 marks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', 'is', 'important', 'for', 'scientific', 'economic', 'social', 'and', 'cultural', 'reasons']\n",
      "['I', 'write', 'a', 'book']\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"S -> S CC S | NP VP\",\n",
    "    \"VP -> VP CC VP | V NP | VP PP | V Adj | V\",\n",
    "    \"NP -> NP CC NP | DT N | NP PP | Adj N | N\",\n",
    "    \"PP -> P NP\",\n",
    "    \"N -> N CC N\",\n",
    "]\n",
    "inputs += [\n",
    "    \"N -> 'academia' | 'analysis' | 'business' | 'computer' | 'corpus' | 'development' | 'growth' | 'industry' | 'information' | 'intelligence' | 'interaction' | 'knowledge' | 'language' | 'name' | 'nlp' | 'range' | 'reason' | 'science' | 'software' | 'variety' | 'areas' | 'humanities' | 'linguistics' | 'methods' | 'people' | 'reasons' | 'technologies' | 'theories'\",\n",
    "    \"V -> 'have' | 'computing' | 'experiencing' | 'deployed' | 'known' | 'are' | 'includes' | 'is'\",\n",
    "    \"Adj -> 'artificial' | 'computational' | 'cultural' | 'economic' | 'human-computer' | 'important' | 'many' | 'new' | 'rapid' | 'scientific' | 'social' | 'wide' | 'working' | 'web'\",\n",
    "    \"P -> 'as' | 'by' | 'for' | 'from' | 'in' | 'of' | 'through' | 'to' | 'within'\",\n",
    "    \"CC -> 'and'\",\n",
    "    \"DT -> 'a' | 'the' | 'this' | 'it' | 'its'\",\n",
    "]  # web, computational\n",
    "grammar = nltk.CFG.fromstring(inputs)\n",
    "chart_parser = nltk.ChartParser(grammar=grammar)\n",
    "# for tokens in word_tokenized_sentences:\n",
    "#     trees = chart_parser.parse(tokens)\n",
    "#     for tree in trees:\n",
    "#         tree.draw()\n",
    "#         print(tree)\n",
    "trees = chart_parser.parse(word_tokenized_sentences[0])\n",
    "for tree in trees:\n",
    "    tree.draw()\n",
    "    print(tree)\n",
    "\n",
    "print(word_tokenized_sentences[0])\n",
    "tokens = nltk.tokenize.word_tokenize(\"I write a book\")\n",
    "print(tokens)\n",
    "inputs = [\n",
    "    \"S -> NP VP\",\n",
    "    \"PP -> P NP\",\n",
    "    \"NP -> Det N | PP NP | Det N PP | 'I'\",\n",
    "    \"VP -> V NP | VP PP | V\",\n",
    "    \"Det -> 'a'\",\n",
    "    \"N -> 'book'\",\n",
    "    \"V -> 'write'\",\n",
    "]\n",
    "# grammar = nltk.CFG.fromstring(inputs)\n",
    "parser = nltk.ChartParser(grammar=grammar)\n",
    "for tree in parser.parse(word_tokenized_sentences[0]):\n",
    "    tree.draw()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{('CC', 'and'),\n ('DT', 'a'),\n ('DT', 'the'),\n ('DT', 'this'),\n ('IN', 'as'),\n ('IN', 'by'),\n ('IN', 'for'),\n ('IN', 'from'),\n ('IN', 'in'),\n ('IN', 'of'),\n ('IN', 'through'),\n ('IN', 'within'),\n ('JJ', 'artificial'),\n ('JJ', 'computational'),\n ('JJ', 'cultural'),\n ('JJ', 'economic'),\n ('JJ', 'human-computer'),\n ('JJ', 'important'),\n ('JJ', 'many'),\n ('JJ', 'new'),\n ('JJ', 'rapid'),\n ('JJ', 'scientific'),\n ('JJ', 'social'),\n ('JJ', 'wide'),\n ('JJ', 'working'),\n ('JJS', 'web'),\n ('NN', 'academia'),\n ('NN', 'analysis'),\n ('NN', 'business'),\n ('NN', 'computer'),\n ('NN', 'corpus'),\n ('NN', 'development'),\n ('NN', 'growth'),\n ('NN', 'industry'),\n ('NN', 'information'),\n ('NN', 'intelligence'),\n ('NN', 'interaction'),\n ('NN', 'knowledge'),\n ('NN', 'language'),\n ('NN', 'name'),\n ('NN', 'nlp'),\n ('NN', 'range'),\n ('NN', 'reason'),\n ('NN', 'science'),\n ('NN', 'software'),\n ('NN', 'variety'),\n ('NNS', 'areas'),\n ('NNS', 'humanities'),\n ('NNS', 'linguistics'),\n ('NNS', 'methods'),\n ('NNS', 'people'),\n ('NNS', 'reasons'),\n ('NNS', 'technologies'),\n ('NNS', 'theories'),\n ('PRP', 'it'),\n ('PRP$', 'its'),\n ('TO', 'to'),\n ('VB', 'have'),\n ('VBG', 'computing'),\n ('VBG', 'experiencing'),\n ('VBN', 'deployed'),\n ('VBN', 'known'),\n ('VBP', 'are'),\n ('VBZ', 'includes'),\n ('VBZ', 'is')}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set((tagged_token[1], tagged_token[0]) for sentence in sentences for tagged_token in TextBlob(sentence.lower()).tags)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('PRP')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# !!! Important !!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am a pig.', 'I lup duck.', 'And, I miss duck']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "tokens = nltk.tokenize.sent_tokenize(\"I am a pig. I lup duck. And, I miss duck\")\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}